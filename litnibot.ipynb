{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffe276c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from telethon import TelegramClient, events\n",
    "from telethon.tl.types import UpdateNewMessage\n",
    "import json\n",
    "import re\n",
    "import openai\n",
    "import math\n",
    "import asyncio\n",
    "import random\n",
    "import os, sys\n",
    "import subprocess\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "\n",
    "from googleapiclient import discovery\n",
    "import httplib2\n",
    "from oauth2client.client import GoogleCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f176292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bot_config import *\n",
    "MAX_RETRYS = 30\n",
    "OPENAI_RETRY_TIMEOUT = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c5370ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libs imported!\n"
     ]
    }
   ],
   "source": [
    "print (\"libs imported!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e443d41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEC_PER_VID_MB = 10\n",
    "NOISE_FILE = 'pink.wav'\n",
    "WORKDIR = 'workdir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b118480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_english_symbols_regex(string: str):\n",
    "    pattern = re.compile(r'[^\\x20-\\x7E]')\n",
    "    return pattern.findall(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f06c1688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_token_count(prompt):\n",
    "    estimated_token_count = 0\n",
    "    words = prompt.split()\n",
    "    for word in words:\n",
    "        if len(non_english_symbols_regex(word)) > 1:\n",
    "            estimated_token_count+=TOKENS_PER_WORD['rus']\n",
    "        else:\n",
    "            estimated_token_count+=TOKENS_PER_WORD['eng']\n",
    "    estimated_token_count = int(estimated_token_count)\n",
    "    return int(estimated_token_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7e22ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tanslate_service():\n",
    "    credentials = GoogleCredentials.get_application_default()\n",
    "#    credentials = GoogleCredentials.get_application_default().create_scoped (\"https://www.googleapis.com/auth/cloud-platform\")\n",
    "    http = httplib2.Http()\n",
    "    credentials.authorize(http)\n",
    "    \n",
    "    creds = GoogleCredentials.get_application_default()\n",
    "    creds.authorize(http)\n",
    "    # Create a service object\n",
    "    translate_service = discovery.build('translate', 'v2')#, http=http)\n",
    "    \n",
    "    # Create a service object\n",
    "#    service = discovery.build('translate', 'v3', http=http, discoveryServiceUrl=DISCOVERY_URL)\n",
    "    return translate_service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ecaa20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_to_lang(texts, target_lang):\n",
    "    response = translate_service.translations().list(q=texts,target=target_lang).execute()\n",
    "    return [i['translatedText'] for i in response['translations']][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53a5c64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio(in_video_path):\n",
    "    try:\n",
    "        sep = '\\\\' if len(in_video_path.split('\\\\')) > len(in_video_path.split('/')) else '/'\n",
    "        aud_path = os.path.join(*in_video_path.split(sep)[:-1], 'audio_'+'.'.join(in_video_path.split(sep)[-1].split('.')[:-1])+'.mp3')\n",
    "        aud = AudioSegment.from_file(in_video_path, \"mp4\")\n",
    "        aud.export(aud_path, format=\"mp3\")\n",
    "        print (f\"Extracted audio to: {aud_path}\")\n",
    "        return aud_path\n",
    "    except Exception as e:\n",
    "        aud_file = None\n",
    "        print (f\"Could NOT extract audio: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dae05e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_media(vide_file, audio_file, res_file):\n",
    "    print (f\"Merging video: {vide_file} + audio: {audio_file}\")\n",
    "    if (audio_file):\n",
    "        aud_cmd = \"-i\", audio_file\n",
    "    else:\n",
    "        aud_cmd = \"\"\n",
    "    \n",
    "    command = [\n",
    "        \"ffmpeg\",\n",
    "        \"-i\", vide_file,\n",
    "        *aud_cmd,\n",
    "        \"-c:v\", \"copy\",\n",
    "        \"-c:a\", \"aac\",\n",
    "        \"-strict\", \"experimental\",\n",
    "        \"-y\",\n",
    "        res_file\n",
    "    ]\n",
    "    try:\n",
    "        subprocess.run(command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        return res_file\n",
    "    except subprocess.CalledProcessError as error:\n",
    "        print(\"Error: FFmpeg command failed with return code\", error.returncode)\n",
    "        print(\"Error output:\", error.stderr.decode(), file=sys.stderr)\n",
    "        return vide_file\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63170a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def rewrite_text (rules, text):\n",
    "    token_used = 0\n",
    "    prompt = rules + '\\n\\n' + text + \"###\"\n",
    "    max_tokens = MAX_REQUEST_LENGHT - CONTIGENCY - estimate_token_count(prompt)\n",
    "    retrys = 0\n",
    "    while retrys < MAX_RETRYS:\n",
    "        retrys+=1\n",
    "        try:\n",
    "            resp = await openai.Completion.acreate(\n",
    "                engine=\"text-davinci-003\",\n",
    "                prompt=prompt,\n",
    "                max_tokens=max_tokens,\n",
    "                n=1,\n",
    "                stop='###',\n",
    "                temperature=TEMPERATURE,\n",
    "                timeout = 15\n",
    "            )\n",
    "            token_used = resp[\"usage\"][\"total_tokens\"] \n",
    "            answer = str(resp.choices[0].text).strip()\n",
    "            break\n",
    "        except Exception as e:\n",
    "            answer = f\"Got error from OpenAI:\\n\\n{str(e)}\"\n",
    "            await asyncio.sleep(OPENAI_RETRY_TIMEOUT)\n",
    "            print(answer)\n",
    "    return answer, token_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "237edb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_video(in_file, angle_max):\n",
    "    sep = '\\\\' if len(in_file.split('\\\\')) > len(in_file.split('/')) else '/'\n",
    "    out_file = os.path.join(*in_file.split(sep)[:-1], 'rotated_'+in_file.split(sep)[-1])\n",
    "    \n",
    "    try:\n",
    "        cap = cv2.VideoCapture(in_file)\n",
    "        width, height, fps= int(cap.get(3)),int(cap.get(4)), (cap.get(5))\n",
    "        center = (int(width/ 2), int(height/ 2))\n",
    "        aspect_ratio = width / height\n",
    "        angle = round((1+ random.random()) * angle_max /2, 5) * random.choice([-1,1])\n",
    "#        scale = np.sqrt(aspect_ratio * np.cos(np.radians(angle)) ** 2 + np.sin(np.radians(angle)) ** 2) / np.sqrt(aspect_ratio)\n",
    "        scale = 1.01\n",
    "        print (f\"Rotating video {angle} degrees, scale {scale}\")\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # or other codecs, e.g. 'mp4v'\n",
    "        out = cv2.VideoWriter(out_file, fourcc, int(fps), (width, height))\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            rot_mat = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "            frame = cv2.warpAffine(frame, rot_mat, (width, height))\n",
    "            out.write(frame)\n",
    "\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        print (\"Rotation Done!\")\n",
    "        return out_file\n",
    "    except Exception as e:\n",
    "        print (f\"Could NOT extract audio: {str(e)}\")\n",
    "        return in_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "528dd76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vid_params(vidfile):\n",
    "    cap = cv2.VideoCapture(vidfile)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = (cap.get(5))\n",
    "    cap.release()\n",
    "    return width, height, fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "657cd0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_work_wm(wmfile, frame_height, frame_width, scale=0.2, of=10, loc='br'):\n",
    "    try:\n",
    "        print (f\"Making work_wm from {wmfile} with W {frame_width}, H {frame_height}\")\n",
    "        watermark = cv2.imread(wmfile, cv2.IMREAD_UNCHANGED)\n",
    "        wm_height, wm_width, _ = watermark.shape\n",
    "        aspect_ratio = wm_width / wm_height\n",
    "        minsidelen = min (frame_height, frame_width)\n",
    "        height, width, channels = watermark.shape\n",
    "        y_offset,x_offset = of, of\n",
    "        if loc[0] == 'c':\n",
    "            scale=0.9\n",
    "            of =0\n",
    "        new_width = int(minsidelen * scale * aspect_ratio)\n",
    "        new_height = int(minsidelen * scale)\n",
    "        watermark = cv2.resize(watermark, (new_width, new_height), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "        if loc[0] == 'c':\n",
    "            x_offset = (frame_width - new_width)//2\n",
    "            y_offset = (frame_height - new_height)//2\n",
    "            print (\"CENTER\")\n",
    "        else:\n",
    "            if loc[0] == 'b':\n",
    "                y_offset = frame_height - new_height - of\n",
    "            if loc[1] == 'r':\n",
    "                x_offset = frame_width - new_width - of\n",
    "        result = np.zeros((frame_height, frame_width, 4), dtype=np.uint8)\n",
    "        result[y_offset:y_offset+new_height, x_offset:x_offset+new_width] = watermark\n",
    "        resfile = os.path.join(WORKDIR, f'wm_{str(random.random())[2:6]}.png')\n",
    "        cv2.imwrite(resfile, result)\n",
    "        print (f\"Made watermark: {resfile}\")\n",
    "        return resfile\n",
    "    except Exception as e:\n",
    "        print (f\"Could NOT make watermark, using as is: {str(e)}\")\n",
    "        return wmfile\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f31d5b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_wm_to_vid(vidfile, wmfile):\n",
    "    sep = '\\\\' if len(vidfile.split('\\\\')) > len(vidfile.split('/')) else '/'\n",
    "    retfile = os.path.join(*vidfile.split(sep)[:-1], 'wm_'+vidfile.split(sep)[-1])\n",
    "    \n",
    "    print (f\"Adding WM to video: {wmfile} to {vidfile}, will write to {retfile}\")\n",
    "    command = [\n",
    "        \"ffmpeg\",\n",
    "        \"-i\", vidfile,\n",
    "        \"-i\", wmfile,\n",
    "        \"-filter_complex\",\n",
    "        \"overlay=(main_w-overlay_w)/2:(main_h-overlay_h)/2\",\n",
    "        \"-y\",\n",
    "        retfile\n",
    "    ]\n",
    "    try:\n",
    "        subprocess.run(command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        print (f\"Added WM to video: {vidfile} to {wmfile}\")\n",
    "        return retfile\n",
    "    except subprocess.CalledProcessError as error:\n",
    "        print(\"Error: FFmpeg command failed with return code\", error.returncode)\n",
    "        print(\"Error output:\", error.stderr.decode(), file=sys.stderr)\n",
    "        return vidfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25bf3880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_some_noise4(in_file, noise):\n",
    "    sep = '\\\\' if len(in_file.split('\\\\')) > len(in_file.split('/')) else '/'\n",
    "    out_file = os.path.join(*in_file.split(sep)[:-1], 'noise_'+in_file.split(sep)[-1])    \n",
    "    print (f\"Making noise with {noise} db\")\n",
    "    sound = AudioSegment.from_file(in_file, format=\"mp3\")\n",
    "    noise_sound = AudioSegment.from_file(NOISE_FILE, format=\"wav\")\n",
    "\n",
    "    repeat_times = (len(sound) + len(noise_sound) - 1) // len(noise_sound)\n",
    "    \n",
    "    noise_sound = noise_sound * repeat_times\n",
    "    noise_sound = noise_sound[:len(sound)]\n",
    "    noise_sound = noise_sound - 40 + noise\n",
    "    \n",
    "    out_sound = sound.overlay(noise_sound, loop=True)\n",
    "\n",
    "    out_sound.export(out_file, format=\"mp3\")\n",
    "    return out_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8867b784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(vidfile, vid_rules):\n",
    "    w, h, fps = get_vid_params(vidfile)\n",
    "    sep = '\\\\' if len(vidfile.split('\\\\')) > len(vidfile.split('/')) else '/'\n",
    "    out_file = os.path.join(*vidfile.split(sep)[:-1], 'out_'+vidfile.split(sep)[-1])\n",
    "    aud_file = extract_audio(vidfile)\n",
    "    if vid_rules.get('angle'):\n",
    "        vidfile = rotate_video(vidfile, vid_rules['angle'])\n",
    "    if (vid_rules['watermark']):\n",
    "        wmloc = vid_rules.get('wm_loc')\n",
    "        if not wmloc or wmloc not in ['br','bl','tr','tl', 'c']:\n",
    "            wmloc = 'br'\n",
    "            print (f\"wm_loc incorrect, using default: bottom-right ('br')\")\n",
    "        wmfile = make_work_wm (vid_rules['watermark'], h, w, scale=0.2, of=10, loc=wmloc)\n",
    "        vidfile = add_wm_to_vid(vidfile, wmfile)\n",
    "        \n",
    "    if (vid_rules['noise'] and aud_file):\n",
    "        aud_file = make_some_noise4 (aud_file, vid_rules['noise'])\n",
    "    outpath = os.path.join(*vidfile.split(sep)[:-1], 'final_'+vidfile.split(sep)[-1])    \n",
    "    video = merge_media(vidfile, aud_file, outpath)\n",
    "    return video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f12ffaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_photo(photo_path, img_rules):\n",
    "    print ('processing image, rules: ', img_rules)\n",
    "    sep = '\\\\' if len(photo_path.split('\\\\')) > len(photo_path.split('/')) else '/'\n",
    "    out_file = os.path.join(*photo_path.split(sep)[:-1], 'out_'+photo_path.split(sep)[-1])\n",
    "    img = Image.open(photo_path).convert(\"RGBA\")\n",
    "    width, height = img.size\n",
    "\n",
    "    if img_rules['rotate']:\n",
    "        print (f\"Rotating by rnd {img_rules['rotate']} degrees\")\n",
    "        img = img.rotate(img_rules['rotate'] * random.random())\n",
    "        \n",
    "    if (img_rules['crop'] ):\n",
    "        print (f\"cropping by rnd {img_rules['crop']}%\")\n",
    "\n",
    "        left = round(width * (random.random() * img_rules['crop'] / 100))\n",
    "        right = round(width * (1-random.random() * img_rules['crop'] / 100))\n",
    "        top = round(height * (random.random() * img_rules['crop'] / 100))\n",
    "        bottom = round(height * (1-random.random() * img_rules['crop'] / 100))\n",
    "\n",
    "        img = img.crop((left, top, right, bottom))\n",
    "\n",
    "    if img_rules['watermark']:\n",
    "        \n",
    "        wmloc = img_rules.get('wm_loc')\n",
    "        if not wmloc or wmloc not in ['br','bl','tr','tl', 'c']:\n",
    "            wmloc = 'br'\n",
    "        wmfile = make_work_wm (img_rules['watermark'], height, width, scale=0.2, of=10, loc=wmloc)\n",
    "        \n",
    "        print (f\"Adding watermark: {img_rules['watermark']}\")        \n",
    "        watermark = Image.open(wmfile)\n",
    "        w_width, w_height = watermark.size\n",
    "#        x = img.width - w_width - 10\n",
    "#        y = img.height - w_height - 10\n",
    "        # Add the watermark to the image\n",
    "#        img.alpha_composite(watermark, (x, y))\n",
    "        img.alpha_composite(watermark, (0, 0))\n",
    "        \n",
    "    img = img.convert(\"RGB\")\n",
    "    img.save(out_file)\n",
    "    \n",
    "    return out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b18e74cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_album(update, rules):\n",
    "    files = []\n",
    "    new_text = \"\"\n",
    "    wd = f\"{update.messages[0].chat_id}_{update.messages[0].id}\"\n",
    "    destination_chat = [_['to'] for _ in channels if _['from']==update.chat_id][0]\n",
    "\n",
    "    for message in update.messages:\n",
    "        if message.photo:\n",
    "            photo_path = os.path.join(WORKDIR, wd, f'input_{str(random.random())[2:5]}.jpg')\n",
    "            await client.download_media(message.photo, photo_path)\n",
    "            new_photo = await process_photo(photo_path, rules['image'])\n",
    "            files.append(new_photo)\n",
    "        elif message.video:\n",
    "            vidfile = os.path.join(WORKDIR, wd, f'invideo_{str(random.random())[2:5]}.mp4')\n",
    "            print (f\"\\nDownloading video to {vidfile}!\")\n",
    "            await client.download_media(message.video, vidfile)\n",
    "            fw_file = process_video(vidfile, rules['video'])\n",
    "            files.append(fw_file)\n",
    "        else:\n",
    "            print (f\"Some other message type: {message.to_dict()}\")\n",
    "\n",
    "        if message.text.strip():\n",
    "            add_text = await get_processed_text (message.text, rules['text'])\n",
    "            new_text += '\\n'+add_text\n",
    "\n",
    "    sent = await client.send_message (destination_chat, file = files, message = new_text.strip()[:1023])\n",
    "    print (\"Album sent:\", sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0b12e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def album_callback(update: UpdateNewMessage):\n",
    "    global processing_queue\n",
    "    upd = update.messages\n",
    "    if update.chat_id in [_['from'] for _ in channels]:\n",
    "        rules = [_['rules'] for _ in channels if _['from']==update.chat_id][0]\n",
    "        fnc = process_album (update, rules)\n",
    "        processing_queue.append(fnc)\n",
    "        print (f\"Added Album to processing (curr {len(processing_queue)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fcf085c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def processor():\n",
    "    print (f\"Processor started!\")\n",
    "    global processing_queue\n",
    "    while True:\n",
    "        q = processing_queue.copy()\n",
    "        for proc in q:\n",
    "            await proc\n",
    "            await asyncio.sleep(1)\n",
    "            print (\"Processed task\")\n",
    "        for proc in q:\n",
    "            processing_queue.remove(proc)\n",
    "        await asyncio.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "528069ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the callback function that will be called when a new message arrives\n",
    "async def message_callback(update: UpdateNewMessage):\n",
    "    global processing_queue\n",
    "    message = update.message\n",
    "    # Forward the message to another chat\n",
    "    if update.message.chat_id in [_['from'] for _ in channels]:\n",
    "        if message.grouped_id:\n",
    "            return\n",
    "        destination_chat = [_['to'] for _ in channels if _['from']==message.chat_id][0]\n",
    "        rules = [_['rules'] for _ in channels if _['from']==message.chat_id][0]\n",
    "        fnc = forward_messages(destination_chat, message, rules)\n",
    "        processing_queue.append(fnc)\n",
    "        print (f\"Added message to processing (curr {len(processing_queue)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fbd7638",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def forward_messages(destination_chat, message, rules):\n",
    "    \n",
    "    if (message.text.strip()):\n",
    "        new_text = await get_processed_text (message.text, rules['text'])\n",
    "        if \"Got error from OpenAI\" in new_text:\n",
    "            await client.send_message(ADMIN_ID, new_text)\n",
    "            new_text = message.text.strip()\n",
    "    else:\n",
    "        print (f\"text will be blank\")\n",
    "        new_text = \"\"\n",
    "\n",
    "        \n",
    "    fw_files = []\n",
    "    wd = f\"{message.chat_id}_{message.id}\"\n",
    "    os.mkdir(os.path.join(WORKDIR, wd))\n",
    "    if (message.photo):\n",
    "        photo_path = os.path.join(WORKDIR, wd, f'input_{str(random.random())[2:5]}.jpg')\n",
    "        await client.download_media(message.photo, photo_path)\n",
    "        fw_file = await process_photo(photo_path, rules['image'])\n",
    "        fw_files.append(fw_file)\n",
    "    elif (message.video):\n",
    "        vidfile = os.path.join(WORKDIR, wd, f'invideo_{str(random.random())[2:5]}.mp4')\n",
    "        print (f\"\\nDownloading video to {vidfile}!\")\n",
    "        await client.download_media(message.video, vidfile)\n",
    "        fw_file = process_video(vidfile, rules['video'])\n",
    "        fw_files.append(fw_file)\n",
    "        \n",
    "    if fw_files:\n",
    "        if len(new_text)<=1023:\n",
    "            print (f\"Sending single message with file and text:\\n{new_text}\")\n",
    "            sent_msg = await client.send_message(destination_chat, file = fw_files, message=new_text)\n",
    "        else:\n",
    "            print (f\"Sending message with file and then with text\")\n",
    "            sent_msg = await client.send_file(destination_chat, file = fw_files)\n",
    "            sent_msg2 = await client.send_message(destination_chat, message=new_text[:4095])\n",
    "    else:\n",
    "        if len (new_text)>0:\n",
    "            print (f\"Sending only text\")\n",
    "            sent_msg = await client.send_message(destination_chat, message=new_text[:4095])        \n",
    "\n",
    "    print (f\"Message sent to {destination_chat} msg:\\n{sent_msg}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e7a5273",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_processed_text(text, rules):\n",
    "    if rules ==\"\":\n",
    "        print (f\"Forwarding text:\\n{text}\")\n",
    "        return text\n",
    "    if text ==\"\":\n",
    "        print (f\"NO text:\\n{text}\")\n",
    "        return \"\"\n",
    "    \n",
    "    if rules['translate']:\n",
    "        print (f\"Translating to {rules['translate']}\")\n",
    "        text = translate_to_lang(text,rules['translate'])\n",
    "    \n",
    "    ret_text = text\n",
    "    if rules['prompt']:\n",
    "        print (f\"Rewriting text with TXT-rule: '{rules['prompt']}' :\\n{text}\")    \n",
    "        text_list = text_to_chunks(text)\n",
    "\n",
    "        ret_text = \"\"\n",
    "        total_tokens = 0\n",
    "        for text in text_list:\n",
    "            new_text, tokens = await rewrite_text(text, rules['prompt'])\n",
    "            ret_text+= f\"\\n{new_text}\"\n",
    "            total_tokens += tokens\n",
    "        print (f\"\\n\\nRewrote using {total_tokens} tokens to: \\n {ret_text}\")\n",
    "    \n",
    "    return ret_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2a8aca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_chunks(text):\n",
    "    MAX_TOKENS = (MAX_REQUEST_LENGHT - CONTIGENCY)//2\n",
    "    total_count = estimate_token_count(text)\n",
    "    n_chunks = math.ceil(total_count / MAX_TOKENS)\n",
    "    max_chunk_token_count = MAX_TOKENS // n_chunks + 50\n",
    "    temp_string = \"\"\n",
    "    temp_count = 0\n",
    "    text_list = []\n",
    "    \n",
    "    for word in re.findall(r\"[\\w']+|[^\\s\\w]\", text):\n",
    "        if temp_count + estimate_token_count(word) <= max_chunk_token_count:\n",
    "            temp_string += word + \" \"\n",
    "            temp_count += estimate_token_count(word)\n",
    "        else:\n",
    "            text_list.append(temp_string.strip())\n",
    "            temp_string = word + \" \"\n",
    "            temp_count = estimate_token_count(word)\n",
    "    text_list.append(temp_string.strip())\n",
    "    \n",
    "    return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c7672ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    print (\"startded main\")\n",
    "    #await client.start(PHONE)\n",
    "    try:\n",
    "        await client.connect()\n",
    "        print (\"Client connected\")\n",
    "        if not await client.is_user_authorized():\n",
    "            await client.send_code_request(PHONE)\n",
    "            code = input('Enter the code: ')\n",
    "            await client.sign_in(PHONE, code)\n",
    "    except errors.SessionPasswordNeededError:\n",
    "        password = input('Two-step verification is enabled. Please enter your password: ')\n",
    "        await client.start(password=password)\n",
    "\n",
    "\n",
    "    dialogs = await client.get_dialogs ()\n",
    "    all_dialogs = \"\"\n",
    "    for dialog in dialogs:\n",
    "        all_dialogs += f\"\\n{dialog.id} \\t {dialog.title}\"\n",
    "    with open(f\"{PHONE}_dialogs.txt\", 'w') as f:\n",
    "        f.write(all_dialogs)\n",
    "    \n",
    "    \n",
    "    # Register the callback function\n",
    "    client.add_event_handler(album_callback, events.Album)\n",
    "    client.add_event_handler(message_callback, events.NewMessage)\n",
    "    \n",
    "\n",
    "    print (f\"Bot up and running\")\n",
    "    # Start polling\n",
    "    await client.run_until_disconnected()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6e869a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a5ee65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ba55a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"./ai-with-radix-09328f41ef89.json\"\n",
    "CHANNEL_FILE= 'channels.json'\n",
    "from channels import *\n",
    "#with open(CHANNEL_FILE, 'r') as f:\n",
    "#    channels = json.load(f)\n",
    "if WORKDIR not in os.listdir():\n",
    "    os.mkdir(WORKDIR)\n",
    "    \n",
    "global processing_queue\n",
    "processing_queue = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e836a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = openai_key\n",
    "client = TelegramClient(PHONE, API_ID, API_HASH)\n",
    "translate_service = get_tanslate_service()\n",
    "\n",
    "workers = [main(), processor()]\n",
    "async def runme (workers):\n",
    "    await asyncio.gather(*workers)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "579c3bb1",
   "metadata": {},
   "source": [
    "if __name__ == '__main__':\n",
    "    asyncio.run(runme(workers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25bfd44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b725d6f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e21ccf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startded main\n",
      "Processor started!\n",
      "Client connected\n",
      "Bot up and running\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/Cellar/python@3.10/3.10.9/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/tasks.py:605\u001b[0m, in \u001b[0;36msleep\u001b[0;34m(delay, result)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 605\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m future\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mCancelledError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m upd\n\u001b[1;32m      2\u001b[0m upd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mworkers)\n",
      "\u001b[0;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "global upd\n",
    "upd = None\n",
    "\n",
    "await asyncio.gather(*workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a992b4f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
